"""
æœ€ç»ˆåˆ†æ - ä¿®å¤æ—¶é—´åºåˆ—é—®é¢˜ï¼Œè¿›è¡Œæ·±åº¦åˆ†æ
"""
import json
import pandas as pd
import numpy as np
import sys
import os
from pathlib import Path
import matplotlib.pyplot as plt
from collections import defaultdict
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from utils.config import get_external_metrics_path

# ä¿®å¤ä¸­æ–‡å­—ç¬¦æ˜¾ç¤ºé—®é¢˜
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS', 'SimSun', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.size'] = 10

def clean_date(date_str):
    """æ¸…ç†æ—¥æœŸå­—ç¬¦ä¸²"""
    if isinstance(date_str, str):
        # å»æ‰ -raw åç¼€
        if '-raw' in date_str:
            date_str = date_str.replace('-raw', '')
        # ç¡®ä¿æ ¼å¼ä¸º YYYY-MM
        if len(date_str) == 7 and '-' in date_str:
            return date_str
    return date_str

def analyze_project_metrics(org, project):
    """åˆ†æå•ä¸ªé¡¹ç›®çš„å®Œæ•´æŒ‡æ ‡"""
    base_dir = get_external_metrics_path()
    project_dir = base_dir / org / project
    
    if not project_dir.exists():
        return None
    
    results = {
        'org': org,
        'project': project,
        'full_name': f"{org}/{project}"
    }
    
    # è¦åˆ†æçš„æŒ‡æ ‡æ–‡ä»¶
    metric_files = {
        'stars': 'stars.json',
        'forks': 'technical_fork.json',
        'activity': 'activity.json',
        'openrank': 'openrank.json',
        'issues': 'issues_new.json',
        'prs': 'change_requests.json',
        'contributors': 'new_contributors.json'
    }
    
    for metric_name, filename in metric_files.items():
        file_path = project_dir / filename
        if file_path.exists():
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                if isinstance(data, dict) and data:
                    # æ¸…ç†æ—¥æœŸ
                    cleaned_data = {}
                    for date_str, value in data.items():
                        clean_dt = clean_date(date_str)
                        if clean_dt:
                            cleaned_data[clean_dt] = value
                    
                    if cleaned_data:
                        # æ’åºæ—¥æœŸ
                        sorted_dates = sorted(cleaned_data.keys())
                        
                        # è·å–æœ€æ–°å€¼
                        latest_date = sorted_dates[-1]
                        latest_value = cleaned_data[latest_date]
                        
                        # è·å–æœ€æ—©å€¼ï¼ˆè®¡ç®—æ€»å¢é•¿ï¼‰
                        if len(sorted_dates) > 1:
                            first_date = sorted_dates[0]
                            first_value = cleaned_data[first_date]
                            total_growth = latest_value - first_value
                            
                            results[f'{metric_name}_latest'] = latest_value
                            results[f'{metric_name}_first'] = first_value
                            results[f'{metric_name}_growth'] = total_growth
                            results[f'{metric_name}_start_date'] = first_date
                            results[f'{metric_name}_end_date'] = latest_date
                        else:
                            results[f'{metric_name}_latest'] = latest_value
            except Exception as e:
                print(f"  è¯»å– {filename} é”™è¯¯: {e}")
    
    return results if len(results) > 3 else None  # è‡³å°‘é™¤äº†åŸºæœ¬ä¿¡æ¯å¤–è¿˜æœ‰æ•°æ®

def analyze_top_projects_across_orgs():
    """åˆ†ææ‰€æœ‰ç»„ç»‡çš„é¡¶çº§é¡¹ç›®"""
    print("=" * 60)
    print("åˆ†ææ‰€æœ‰ç»„ç»‡çš„é¡¶çº§é¡¹ç›®")
    print("=" * 60)
    
    base_dir = get_external_metrics_path()
    all_projects_data = []
    
    # åªåˆ†æä¸€äº›çŸ¥åç»„ç»‡ï¼ˆé¿å…å¤ªå¤šæ•°æ®ï¼‰
    top_orgs_to_analyze = [
        'microsoft', 'google', 'facebook', 'apache',
        'tensorflow', 'kubernetes', 'docker', 'nodejs',
        'python', 'golang', 'rust-lang', 'pytorch'
    ]
    
    org_count = 0
    for org in base_dir.iterdir():
        if not org.is_dir():
            continue
        
        org_name = org.name
        
        # å¦‚æœæŒ‡å®šäº†ç»„ç»‡åˆ—è¡¨ï¼Œåªåˆ†æè¿™äº›ç»„ç»‡
        if top_orgs_to_analyze and org_name not in top_orgs_to_analyze:
            continue
        
        print(f"\nğŸ“¦ åˆ†æç»„ç»‡: {org_name}")
        
        # åˆ†æç»„ç»‡ä¸‹çš„æ‰€æœ‰é¡¹ç›®
        project_count = 0
        for project_dir in org.iterdir():
            if not project_dir.is_dir():
                continue
            
            project_name = project_dir.name
            project_data = analyze_project_metrics(org_name, project_name)
            
            if project_data:
                all_projects_data.append(project_data)
                project_count += 1
        
        print(f"  æ‰¾åˆ° {project_count} ä¸ªé¡¹ç›®")
        org_count += 1
        
        # æ§åˆ¶åˆ†æçš„ç»„ç»‡æ•°é‡
        if org_count >= 10 and len(all_projects_data) >= 50:
            print(f"\nå·²åˆ†æ {org_count} ä¸ªç»„ç»‡ï¼Œ{len(all_projects_data)} ä¸ªé¡¹ç›®ï¼Œåœæ­¢åˆ†ææ›´å¤š")
            break
    
    if all_projects_data:
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(all_projects_data)
        
        # ä¿å­˜åŸå§‹æ•°æ®
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)
        df.to_csv('output/all_top_projects_metrics.csv', index=False, encoding='utf-8-sig')
        
        print(f"\nâœ… æˆåŠŸåˆ†æäº† {len(df)} ä¸ªé¡¹ç›®")
        return df
    else:
        print("âŒ æ²¡æœ‰æ”¶é›†åˆ°é¡¹ç›®æ•°æ®")
        return None

def analyze_project_growth(df):
    """åˆ†æé¡¹ç›®å¢é•¿æƒ…å†µ"""
    print(f"\n" + "=" * 60)
    print("é¡¹ç›®å¢é•¿åˆ†æ")
    print("=" * 60)
    
    if df is None or df.empty:
        return
    
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    df = df.copy()
    
    # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
    required_cols = ['stars_latest', 'openrank_latest', 'activity_latest']
    available_cols = [col for col in required_cols if col in df.columns]
    
    if len(available_cols) >= 2:
        # å½’ä¸€åŒ–æ•°æ®
        for col in available_cols:
            if col in df.columns and df[col].max() > df[col].min():
                df[f'{col}_norm'] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())
            else:
                df[f'{col}_norm'] = 0
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
        weights = {'stars_latest_norm': 0.3, 'openrank_latest_norm': 0.4, 'activity_latest_norm': 0.3}
        df['composite_score'] = 0
        
        for col, weight in weights.items():
            if col in df.columns:
                df['composite_score'] += df[col] * weight
    
    # æŒ‰OpenRankæ’åºï¼ˆè¿™æ˜¯æ ¸å¿ƒæŒ‡æ ‡ï¼‰
    if 'openrank_latest' in df.columns:
        df_sorted_by_openrank = df.sort_values('openrank_latest', ascending=False)
        
        print(f"\nğŸ† Top 20 é¡¹ç›®ï¼ˆæŒ‰OpenRankå½±å“åŠ›ï¼‰:")
        print("-" * 80)
        for i, (idx, row) in enumerate(df_sorted_by_openrank.head(20).iterrows(), 1):
            print(f"{i:2d}. {row['full_name']:45s} "
                  f"ğŸ“Š {row['openrank_latest']:7.1f} "
                  f"â­ {row.get('stars_latest', 'N/A'):6,.0f} "
                  f"ğŸ“ˆ {row.get('activity_latest', 'N/A'):6,.0f}")
    
    # æŒ‰æœˆåº¦Starså¢é•¿æ¨¡å¼å˜åŒ–æ’åº
    if 'stars_growth' in df.columns:
        df_sorted_by_growth = df.sort_values('stars_growth', ascending=False)
        
        print(f"\nğŸ“ˆ Top 20 é¡¹ç›®ï¼ˆæŒ‰æœˆåº¦Starså¢é•¿æ¨¡å¼å˜åŒ–ï¼‰:")
        print("-" * 80)
        print("è¯´æ˜: æ­£å€¼è¡¨ç¤ºæœ€æ–°æœˆå¢é•¿è¶…è¿‡åˆæœŸï¼Œè´Ÿå€¼è¡¨ç¤ºæœ€æ–°æœˆå¢é•¿ä½äºåˆæœŸ")
        for i, (idx, row) in enumerate(df_sorted_by_growth.head(20).iterrows(), 1):
            growth = row['stars_growth']
            growth_str = f"+{growth:,.0f}" if growth >= 0 else f"{growth:,.0f}"
            print(f"{i:2d}. {row['full_name']:45s} {growth_str:>10s}")
    
    # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
    if 'composite_score' in df.columns:
        df_sorted_by_composite = df.sort_values('composite_score', ascending=False)
        
        print(f"\nğŸŒŸ Top 20 é¡¹ç›®ï¼ˆæŒ‰ç»¼åˆè¯„åˆ†ï¼‰:")
        print("-" * 80)
        for i, (idx, row) in enumerate(df_sorted_by_composite.head(20).iterrows(), 1):
            score = row['composite_score']
            print(f"{i:2d}. {row['full_name']:45s} è¯„åˆ†: {score:.3f}")
    
    return df

def create_growth_visualizations(df):
    """åˆ›å»ºå¢é•¿å¯è§†åŒ–å›¾è¡¨"""
    print(f"\n" + "=" * 60)
    print("åˆ›å»ºå¢é•¿å¯è§†åŒ–å›¾è¡¨")
    print("=" * 60)
    
    if df is None or df.empty:
        return
    
    # åˆ›å»ºå›¾è¡¨ç›®å½•
    charts_dir = Path("output/charts")
    charts_dir.mkdir(exist_ok=True)
    
    # 1. OpenRankåˆ†å¸ƒå›¾
    plt.figure(figsize=(14, 10))
    
    if 'openrank_latest' in df.columns:
        # 1.1 Top 20é¡¹ç›®OpenRank
        plt.subplot(2, 2, 1)
        top_20_openrank = df.nlargest(20, 'openrank_latest')
        top_20_openrank['short_name'] = top_20_openrank['full_name'].apply(
            lambda x: x.split('/')[-1][:20]
        )
        
        bars = plt.barh(range(len(top_20_openrank)), top_20_openrank['openrank_latest'])
        plt.yticks(range(len(top_20_openrank)), top_20_openrank['short_name'])
        plt.xlabel('OpenRank Score')
        plt.title('Top 20 Projects by OpenRank (Influence)')
        plt.gca().invert_yaxis()
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, top_20_openrank['openrank_latest']):
            plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, 
                    f' {value:.1f}', va='center')
    
    # 1.2 OpenRank vs Stars æ•£ç‚¹å›¾
    if 'openrank_latest' in df.columns and 'stars_latest' in df.columns:
        plt.subplot(2, 2, 2)
        
        plt.scatter(df['stars_latest'], df['openrank_latest'], alpha=0.6, s=30)
        plt.xlabel('Monthly New Stars')
        plt.ylabel('OpenRank Score')
        plt.title('OpenRank vs Monthly Stars')
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ è¶‹åŠ¿çº¿
        if len(df) > 1:
            z = np.polyfit(df['stars_latest'], df['openrank_latest'], 1)
            p = np.poly1d(z)
            x_line = np.linspace(df['stars_latest'].min(), df['stars_latest'].max(), 100)
            plt.plot(x_line, p(x_line), 'r--', alpha=0.5, label='Trend line')
            plt.legend()
    
    # 1.3 Activityåˆ†å¸ƒ
    if 'activity_latest' in df.columns:
        plt.subplot(2, 2, 3)
        plt.hist(df['activity_latest'], bins=30, alpha=0.7, edgecolor='black')
        plt.xlabel('Activity Score')
        plt.ylabel('Number of Projects')
        plt.title('Activity Distribution')
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        mean_activity = df['activity_latest'].mean()
        median_activity = df['activity_latest'].median()
        plt.axvline(mean_activity, color='red', linestyle='--', 
                   label=f'Mean: {mean_activity:.1f}')
        plt.axvline(median_activity, color='green', linestyle='--', 
                   label=f'Median: {median_activity:.1f}')
        plt.legend()
    
    # 1.4 æŒ‡æ ‡ç›¸å…³æ€§çƒ­åŠ›å›¾
    plt.subplot(2, 2, 4)
    numeric_cols = ['stars_latest', 'forks_latest', 'activity_latest', 
                   'openrank_latest', 'issues_latest', 'prs_latest']
    numeric_cols = [col for col in numeric_cols if col in df.columns]
    
    if len(numeric_cols) >= 3:
        corr_matrix = df[numeric_cols].corr()
        
        # ä½¿ç”¨æ•°å€¼æ˜¾ç¤ºï¼Œé¿å…ä¸­æ–‡é—®é¢˜
        import seaborn as sns
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
                   square=True, fmt='.2f', cbar_kws={'label': 'Correlation'})
        plt.title('Metrics Correlation Matrix')
    
    plt.suptitle('GitHub Top Projects Analysis', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig('output/charts/growth_analysis_overview.png', dpi=150, bbox_inches='tight')
    print(f"ğŸ“Š å›¾è¡¨1å·²ä¿å­˜: output/charts/growth_analysis_overview.png")
    
    # 2. æ—¶é—´åºåˆ—åˆ†æï¼ˆé€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§é¡¹ç›®ï¼‰
    print(f"\nğŸ“ˆ æ—¶é—´åºåˆ—åˆ†æï¼ˆä»£è¡¨æ€§é¡¹ç›®ï¼‰:")
    analyze_time_series_for_selected_projects()
    
    plt.show()

def analyze_time_series_for_selected_projects():
    """åˆ†æé€‰å®šé¡¹ç›®çš„æ—¶é—´åºåˆ—"""
    base_dir = get_external_metrics_path()
    
    # é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§é¡¹ç›®
    selected_projects = [
        ("microsoft", "vscode"),
        ("facebook", "react"),
        ("tensorflow", "tensorflow"),
        ("kubernetes", "kubernetes")
    ]
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('Project Growth Time Series Analysis', fontsize=16, fontweight='bold')
    
    for idx, (org, project) in enumerate(selected_projects):
        ax = axes[idx//2, idx%2]
        
        project_dir = base_dir / org / project
        stars_file = project_dir / "stars.json"
        
        if stars_file.exists():
            try:
                with open(stars_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                if isinstance(data, dict) and data:
                    # æ¸…ç†æ•°æ®
                    clean_data = {}
                    for date_str, value in data.items():
                        clean_dt = clean_date(date_str)
                        if clean_dt and '-' in clean_dt:
                            # åªä¿ç•™æ ‡å‡†æ ¼å¼çš„æ—¥æœŸ
                            if len(clean_dt) == 7:
                                clean_data[clean_dt] = value
                    
                    if clean_data:
                        # è½¬æ¢ä¸ºDataFrame
                        dates = sorted(clean_data.keys())
                        values = [clean_data[d] for d in dates]
                        
                        # åªæ˜¾ç¤ºå¹´ä»½-æœˆä»½ï¼Œé¿å…å¤ªæ‹¥æŒ¤
                        display_dates = []
                        for i, d in enumerate(dates):
                            if i % 12 == 0 or i == len(dates)-1:  # æ¯å¹´æ˜¾ç¤ºä¸€ä¸ªæ ‡ç­¾
                                display_dates.append(d)
                            else:
                                display_dates.append('')
                        
                        # è½¬æ¢ä¸ºç´¯è®¡æ€»æ•°ï¼ˆå°†æ‰€æœ‰æœˆåº¦æ–°å¢ç›¸åŠ ï¼‰
                        cumulative_values = []
                        running_total = 0
                        for value in values:
                            running_total += value
                            cumulative_values.append(running_total)
                        
                        # ç»˜åˆ¶å›¾è¡¨ï¼ˆä½¿ç”¨ç´¯è®¡æ•°æ®æ˜¾ç¤ºå¹³æ»‘å¢é•¿ï¼‰
                        ax.plot(range(len(dates)), cumulative_values, marker='o', markersize=3, linewidth=2)
                        ax.set_title(f'{org}/{project}')
                        ax.set_xlabel('Time (Months)')
                        ax.set_ylabel('Cumulative Total Stars')
                        ax.grid(True, alpha=0.3)
                        
                        # è®¾ç½®xè½´æ ‡ç­¾
                        ax.set_xticks(range(len(dates)))
                        ax.set_xticklabels(display_dates, rotation=45, ha='right')
                        
                        # è®¡ç®—å’Œæ˜¾ç¤ºå¢é•¿ï¼ˆä½¿ç”¨ç´¯è®¡æ•°æ®ï¼‰
                        if len(cumulative_values) >= 2:
                            total_stars = cumulative_values[-1]
                            avg_monthly = total_stars / len(cumulative_values)
                            ax.text(0.05, 0.95, 
                                   f'Total Stars: {total_stars:,.0f}\nAvg Monthly: {avg_monthly:.0f}',
                                   transform=ax.transAxes,
                                   verticalalignment='top',
                                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
            except Exception as e:
                ax.text(0.5, 0.5, f'Error: {e}', ha='center', va='center')
                ax.set_title(f'{org}/{project} - Error')
        else:
            ax.text(0.5, 0.5, 'Data not found', ha='center', va='center')
            ax.set_title(f'{org}/{project}')
    
    plt.tight_layout()
    plt.savefig('output/charts/time_series_analysis.png', dpi=150, bbox_inches='tight')
    print(f"ğŸ“Š å›¾è¡¨2å·²ä¿å­˜: output/charts/time_series_analysis.png")

def generate_final_report(df):
    """ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š"""
    print(f"\n" + "=" * 60)
    print("ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
    if df is None or df.empty:
        return
    
    # ç”Ÿæˆå„ç§æ’è¡Œæ¦œ
    reports_dir = Path("output/reports")
    reports_dir.mkdir(exist_ok=True)
    
    # 1. OpenRankæ’è¡Œæ¦œ
    if 'openrank_latest' in df.columns:
        openrank_top = df.nlargest(50, 'openrank_latest')[['full_name', 'openrank_latest', 
                                                          'stars_latest', 'activity_latest']]
        openrank_top.to_csv('output/reports/top_50_by_openrank.csv', index=False, encoding='utf-8-sig')
        print(f"ğŸ“‹ OpenRankæ’è¡Œæ¦œå·²ä¿å­˜")
    
    # 2. æ´»è·ƒåº¦æ’è¡Œæ¦œ
    if 'activity_latest' in df.columns:
        activity_top = df.nlargest(50, 'activity_latest')[['full_name', 'activity_latest', 
                                                          'openrank_latest', 'stars_latest']]
        activity_top.to_csv('output/reports/top_50_by_activity.csv', index=False, encoding='utf-8-sig')
        print(f"ğŸ“‹ æ´»è·ƒåº¦æ’è¡Œæ¦œå·²ä¿å­˜")
    
    # 3. æœˆåº¦Starså¢é•¿æ¨¡å¼å˜åŒ–æ’è¡Œæ¦œ
    if 'stars_growth' in df.columns:
        growth_top = df.nlargest(50, 'stars_growth')[['full_name', 'stars_growth', 
                                                     'stars_latest', 'openrank_latest']]
        growth_top.to_csv('output/reports/top_50_by_star_growth.csv', index=False, encoding='utf-8-sig')
        print(f"ğŸ“‹ æœˆåº¦Starså¢é•¿æ¨¡å¼å˜åŒ–æ’è¡Œæ¦œå·²ä¿å­˜")
    
    # 4. ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
    with open('output/reports/summary_report.txt', 'w', encoding='utf-8') as f:
        f.write("GitHub Top Projects Analysis Report\n")
        f.write("=" * 60 + "\n\n")
        
        f.write(f"Total Projects Analyzed: {len(df)}\n")
        f.write(f"Time Range: 2015-2023\n\n")
        
        if 'openrank_latest' in df.columns:
            f.write("Key Statistics:\n")
            f.write(f"- Average OpenRank: {df['openrank_latest'].mean():.1f}\n")
            f.write(f"- Max OpenRank: {df['openrank_latest'].max():.1f}\n")
            f.write(f"- Min OpenRank: {df['openrank_latest'].min():.1f}\n\n")
        
        if 'stars_latest' in df.columns:
            f.write("Monthly New Stars Statistics:\n")
            f.write(f"- Average monthly stars: {df['stars_latest'].mean():.0f}\n")
            f.write(f"- Max monthly stars: {df['stars_latest'].max():.0f}\n")
            f.write(f"- Total analyzed: {df['stars_latest'].sum():,.0f}\n\n")
        
        f.write("Top 10 Projects by OpenRank:\n")
        if 'openrank_latest' in df.columns:
            top_10 = df.nlargest(10, 'openrank_latest')
            for i, (_, row) in enumerate(top_10.iterrows(), 1):
                f.write(f"{i:2d}. {row['full_name']:45s} OpenRank: {row['openrank_latest']:7.1f}\n")
    
    print(f"\nğŸ“„ æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜: output/reports/summary_report.txt")
    print(f"ğŸ“ æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶åœ¨ output/reports/ ç›®å½•ä¸­")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ GitHub Top 300 é¡¹ç›®æ·±åº¦åˆ†æ")
    print("=" * 60)
    
    # æ­¥éª¤1ï¼šåˆ†ææ‰€æœ‰é¡¶çº§é¡¹ç›®
    print("1. æ”¶é›†å’Œåˆ†æé¡¹ç›®æ•°æ®...")
    df = analyze_top_projects_across_orgs()
    
    if df is None:
        print("âŒ æ²¡æœ‰æ•°æ®å¯åˆ†æ")
        return
    
    # æ­¥éª¤2ï¼šåˆ†æå¢é•¿æƒ…å†µ
    print("\n2. åˆ†æé¡¹ç›®å¢é•¿æƒ…å†µ...")
    df = analyze_project_growth(df)
    
    # æ­¥éª¤3ï¼šåˆ›å»ºå¯è§†åŒ–å›¾è¡¨
    print("\n3. åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
    create_growth_visualizations(df)
    
    # æ­¥éª¤4ï¼šç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    print("\n4. ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    generate_final_report(df)
    
    print(f"\n" + "=" * 60)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("=" * 60)
    print(f"ğŸ“Š åˆ†æäº† {len(df)} ä¸ªé¡¹ç›®")
    print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  output/all_top_projects_metrics.csv - æ‰€æœ‰é¡¹ç›®æ•°æ®")
    print(f"  output/charts/growth_analysis_overview.png - ç»¼åˆåˆ†æå›¾è¡¨")
    print(f"  output/charts/time_series_analysis.png - æ—¶é—´åºåˆ—å›¾è¡¨")
    print(f"  output/reports/ - å„ç§æ’è¡Œæ¦œå’ŒæŠ¥å‘Š")

if __name__ == "__main__":
    main()